# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11lr8Zs79UyvoVpF2-FLI9iZChTWCRCin
"""

import pandas as pd
df=pd.read_csv('/content/phis.csv')

df.shape

df=df.drop_duplicates()
df.shape

# Check for missing values
print(df.isnull().sum())

# Check percentage of missing values
print((df.isnull().sum() / len(df)) * 100)

df['receiver'] = df['receiver'].fillna(df['receiver'].mode()[0])
df['subject']=df['subject'].fillna(df['subject'].mode()[0])
print(df.isnull().sum())

df.describe(include ='all')

import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(6, 4))
sns.countplot(x='label', data=df)
plt.title('Distribution of Labels')
plt.show()

# 5. Distribution of the presence of URLs
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(6, 4))
sns.countplot(x='urls', data=df)
plt.title('Distribution of URL Presence')
plt.show()

# 6. Most frequent words in the email subject
from wordcloud import WordCloud

# Combine all subject lines into one string
subject_text = ' '.join(df['subject'].astype(str))

# Generate a word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(subject_text)

# Plot the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Email Subjects')
plt.show()

# 7. Most frequent words in the email body
# Combine all body text into one string
body_text = ' '.join(df['body'].astype(str))

# Generate a word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(body_text)

# Plot the word cloud
#print(body_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Email Bodies')
plt.show()

#8. Correlation matrix for numerical columns
import seaborn as sns
import matplotlib.pyplot as plt

# Select only numerical columns
numerical_df = df.select_dtypes(include=['number'])

plt.figure(figsize=(8, 6))
sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()

# 9. Length of the body text
df['body_length'] = df['body'].apply(len)

plt.figure(figsize=(6, 4))
sns.histplot(df['body_length'], bins=50, kde=True)
plt.title('Distribution of Email Body Lengths')
plt.show()

# 10. Average body length by label
plt.figure(figsize=(6, 4))
sns.boxplot(x='label', y='body_length', data=df)
plt.title('Email Body Length by Label')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
import re

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)  # Remove special characters
    return text

df['cleaned_body'] = df['body'].apply(preprocess_text)

# Extract features using TF-IDF
vectorizer = TfidfVectorizer(max_features=5000)
X_text = vectorizer.fit_transform(df['cleaned_body'])

# Convert the sparse matrix to a DataFrame
X_text_df = pd.DataFrame(X_text.toarray(), index=df.index)
X_text_df.columns = X_text_df.columns.astype(str)

# Combine TF-IDF features with the 'urls' binary feature
X = pd.concat([X_text_df, df[['urls']].reset_index(drop=True)], axis=1)
X.columns = X.columns.astype(str)  # Ensure all column names are strings

# Extract the label column
y = df['label'].reset_index(drop=True)

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
# Import the correct class for Support Vector Machine
from sklearn.svm import SVC
from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
import re

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)  # Remove special characters
    return text

df['cleaned_body'] = df['body'].apply(preprocess_text)

models = {
    "Logistic Regression": LogisticRegression(),
    #"Support Vector Machine": SVC(kernel='linear', probability=True, random_state=42), # Use SVC instead of SVM
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(),
    "Extra Trees": ExtraTreesClassifier(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier()
    }
trained_models={}
# Train and evaluate each model
for model_name, model in models.items():
    print(f"Training and Evaluating: {model_name}")
    pipeline = Pipeline([('model', model)])
    trained_models[model_name] = pipeline
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Display classification report and accuracy
    print(f"\n{model_name} Classification Report:\n")
    print(classification_report(y_test, y_pred))
    print(f"Accuracy: {accuracy:.2f}\n")
    print("="*60)



import pandas as pd

def predict_email_phishing(subject, body, model_name):
    # Combine subject and body
    text = subject + " " + body

    # 1. Transform the text using the same vectorizer used during training
    text_vectorized = vectorizer.transform([text])

    # 2. Convert the sparse matrix to a DataFrame with the correct column names
    text_vectorized_df = pd.DataFrame(text_vectorized.toarray())
    text_vectorized_df.columns = X_text_df.columns  # Use the original column names

    # 3. Create a DataFrame for 'urls' feature (Assuming it's 1 if URL is present, 0 otherwise)
    urls_df = pd.DataFrame({'urls': [1 if 'http://' in text or 'https://' in text else 0]})

    # 4. Concatenate the DataFrames to match the training data structure
    input_data = pd.concat([text_vectorized_df, urls_df], axis=1)

    # Predict using the specified model
    pipeline = trained_models[model_name]
    prediction = pipeline.predict(input_data)


    # Return the prediction result
    return prediction[0]

# Example prediction using Logistic Regression
subject_example = "Never agree to be a loser"
body_example = "Buck up, your troubles caused by small dimension will soon be over!Become a lover no woman will be able to resist! http://whitedone.com/come. Even as Nazi tanks were rolling down the streets, the dreamersphilosopher or a journalist. He was still not sure.I do the same"
model_name = 'Logistic Regression'  # You can choose any trained model
is_phished = predict_email_phishing(subject_example, body_example, model_name)

# Example prediction using Logistic Regression
subject_example = "Wekalist Digest, Vol 60, Issue 10"
body_example = "Send Wekalist mailing list submissions to iuxxdkqk@list.scms.waikato.ac.nzTo subscribe or unsubscribe via the World Wide Web, visithttps://list.scms.waikato.ac.nz/mailman/listinfo/wekalistor, via email, send a message with subject or body 'help' toohwwlejs-pbfotbp@list.scms.waikato.ac.nzYou can reach the person managing the list atpobypuhs-hvhzj@list.scms.waikato.ac.nzWhen replying, please edit your Subject line so it is more specificthan 'Re: Contents of Wekalist digest...'Todays Topics:1. RE: Weka 3.5.7.exe installation problems (Danilovich, Yann)2. Question (bug?) (Uday Kamath)3. Event Sequence Mining (Budziak, G.)4. RE: Question (bug?) (Cristina Torres)5. RE: where can i find algorithms explanation(Nanda, Subrat (GE, Research))----------------------------------------------------------------------"
model_name = 'Logistic Regression'  # You can choose any trained model
is_phished = predict_email_phishing(subject_example, body_example, model_name)

print(f"Model: {model_name}")
print(f"Phished: {1 if is_phished else 0}")

subject_example=" Urgent: Account Verification Needed"
body_example="Dear Customer,We detected suspicious activity on your account, and it has been temporarily locked for your security. Please verify your details immediately to regain access.Click here to verify your account:[https://secure-login.bankofamericca.com/verify-account]Failure to verify within 24 hours will result in permanent account suspension.Sincerely,Bank of America Support Team"
model_name='Logistic Regression'
is_phished=predict_email_phishing(subject_example,body_example,model_name)
print(f"Model: {model_name}")
print(f"Phished:{1 if is_phished else 0}")

subject_example= "Urgent: Account Suspended"
body_example= "Dear Valued Customer,We have detected unusual activity on your account. For your security, we have temporarily suspended your account. Please verify your details immediately to restore access.Click here to verify: [malicious link]Failure to act within 24 hours will result in permanent account suspension.Thank you for your cooperation,Bank Support Team"
model_name='Logistic Regression'
is_phished= predict_email_phishing(subject_example,body_example,model_name)
print(f"Model: {model_name}")
print(f"Phished:{1 if is_phished else 0}")